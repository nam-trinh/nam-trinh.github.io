---
title: "Generative Adversarial Network-Based Semi-supervised Learning for Pathological Speech Classification"
collection: publications
permalink: /publication/2021-03-23-paper-generative
excerpt: 'This paper is about applying generative adversarial networks in a semi-supervised learning approach'
date: 2021-03-23
venue: 'International Conference on Statistical Language and Speech Processing'
paperurl: 'http://doras.dcu.ie/25067/1/SLSP2020_Nam_DOB.pdf'
citation: 'Trinh N.H., O’Brien D. (2020) Generative Adversarial Network-Based Semi-supervised Learning for Pathological Speech Classification. In: Espinosa-Anke L., Martín-Vide C., Spasić I. (eds) Statistical Language and Speech Processing. SLSP 2020. Lecture Notes in Computer Science, vol 12379. Springer, Cham. https://doi.org/10.1007/978-3-030-59430-5_14'
---
A challenge in applying machine learning algorithms to pathological speech classification is the labelled data shortage problem. Labelled data acquisition often requires significant human effort and time-consuming experimental design. Further, for medical applications, privacy and ethical issues must be addressed where patient data is collected. While labelled data are expensive and scarce, unlabelled data are typically inexpensive and plentiful. In this paper, we propose a semi-supervised learning approach that employs a generative adversarial network to incorporate both labelled and unlabelled data into training. We observe a promising accuracy gain with this approach compared to a baseline convolutional neural network trained only on labelled pathological speech data.

[Download paper here](http://doras.dcu.ie/25067/1/SLSP2020_Nam_DOB.pdf)

Recommended citation: Trinh N.H., O’Brien D. (2020) Generative Adversarial Network-Based Semi-supervised Learning for Pathological Speech Classification. In: Espinosa-Anke L., Martín-Vide C., Spasić I. (eds) Statistical Language and Speech Processing. SLSP 2020. Lecture Notes in Computer Science, vol 12379. Springer, Cham. https://doi.org/10.1007/978-3-030-59430-5_14.